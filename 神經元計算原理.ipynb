{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1yRUPdv8g58x4h6ffn1XRpjC9Whco_B8G",
      "authorship_tag": "ABX9TyOlKW6KGCaEhvD4Q0bKxmWj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wcliao1962/2025_DL/blob/master/%E7%A5%9E%E7%B6%93%E5%85%83%E8%A8%88%E7%AE%97%E5%8E%9F%E7%90%86.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "電腦神經元是人工神經網絡的基本單元，其計算過程模仿生物神經元的工作方式。以下是電腦神經元如何進行計算的詳細解說：\n",
        "\n",
        "### 1. 輸入\n",
        "每個神經元接收來自其他神經元或輸入層的多個輸入信號，這些信號通常表示為向量 $( x = [x_1, x_2, ..., x_n] $)。\n",
        "\n",
        "### 2. 加權\n",
        "每個輸入信號 $( x_i $) 都有一個對應的權重 $( w_i $)，表示該輸入對神經元的重要性。加權後的輸入為 $( w_i \\times x_i $)。\n",
        "\n",
        "### 3. 加總\n",
        "神經元將所有加權輸入相加，並加上一個偏置項 $( b $)，形成加權總和 $( z $)：\n",
        "\n",
        "$$ z = \\sum_{i=1}^{n} w_i \\times x_i + b $$\n",
        "\n",
        "### 4. 激活函數\n",
        "加權總和 $( z $) 通過激活函數 $( f $) 進行非線性轉換，得到神經元的輸出 $( a $)：\n",
        "$$ a = f(z) $$\n",
        "常見的激活函數包括：\n",
        "- **Sigmoid**: $ f(z) = \\frac{1}{1 + e^{-z}} $\n",
        "- **ReLU**: $ f(z) = \\max(0, z) $\n",
        "- **Tanh**: $ f(z) = \\tanh(z) $\n",
        "\n",
        "### 5. 輸出\n",
        "激活函數的輸出 $( a $) 作為該神經元的輸出，傳遞給下一層神經元或作為最終輸出。\n",
        "\n",
        "### 總結\n",
        "電腦神經元的計算過程包括輸入、加權、加總、激活函數處理和輸出。這些步驟使神經元能夠處理和傳遞信息，進而實現複雜的計算任務。\n",
        "\n",
        "### 公式總結\n",
        "$$ a = f\\left(\\sum_{i=1}^{n} w_i \\times x_i + b\\right) $$\n",
        "\n",
        "這個過程是人工神經網絡進行信息處理和學習的基礎。"
      ],
      "metadata": {
        "id": "wQwpuOwTuR5y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "175pKSFkuiSY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "交叉熵損失函數（Cross Entropy Loss Function）是機器學習和深度學習中常用的一種損失函數，特別是在分類任務中。它衡量的是模型預測的概率分佈與真實標籤的概率分佈之間的差異。\n",
        "\n",
        "對於一個分類問題，假設我們有 $( C $) 個類別，真實標籤為 $( y $)（通常以 one-hot 編碼表示），模型的預測概率為 \\( \\hat{y} \\)，則交叉熵損失函數可以表示為：\n",
        "\n",
        "$$\n",
        "\\text{CrossEntropy}(y, \\hat{y}) = -\\sum_{i=1}^{C} y_i \\log(\\hat{y}_i)\n",
        "$$\n",
        "\n",
        "其中：\n",
        "- $( y_i $) 是第 $( i $) 個類別的真實標籤（0 或 1）。\n",
        "- $( \\hat{y}_i $) 是模型預測的第 $( i $) 個類別的概率。\n",
        "\n",
        "### 二元分類的情況\n",
        "對於二元分類問題（\\( C = 2 \\)），交叉熵損失函數可以簡化為：\n",
        "\n",
        "$$\n",
        "\\text{BinaryCrossEntropy}(y, \\hat{y}) = -\\left[ y \\log(\\hat{y}) + (1 - y) \\log(1 - \\hat{y}) \\right]\n",
        "$$\n",
        "\n",
        "其中：\n",
        "- $( y $) 是真實標籤（0 或 1）。\n",
        "- $( \\hat{y} $) 是模型預測的正類概率。\n",
        "\n",
        "### 實際應用\n",
        "在深度學習框架中（如 TensorFlow 或 PyTorch），交叉熵損失函數通常已經內建，可以直接調用。例如：\n",
        "\n",
        "- **PyTorch**:\n",
        "  ```python\n",
        "  import torch.nn as nn\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  loss = criterion(output, target)\n",
        "  ```\n",
        "\n",
        "- **TensorFlow/Keras**:\n",
        "  ```python\n",
        "  from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "\n",
        "  criterion = CategoricalCrossentropy()\n",
        "  loss = criterion(y_true, y_pred)\n",
        "  ```\n",
        "\n",
        "### 注意事項\n",
        "1. **Softmax 函數**：在多類別分類中，通常會在模型的最後一層使用 Softmax 函數，將輸出轉換為概率分佈。\n",
        "2. **數值穩定性**：在實際計算中，為了避免對數函數的輸入為 0 或 1 導致數值不穩定，通常會對預測值進行裁剪（例如，限制在 $([ \\epsilon, 1-\\epsilon ]$) 範圍內）。\n",
        "\n",
        "希望這能幫助你理解交叉熵損失函數！如果有進一步的問題，歡迎隨時詢問。"
      ],
      "metadata": {
        "id": "HqZzv5YUBxFL"
      }
    }
  ]
}