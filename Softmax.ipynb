{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO7+TeBgVYbFFT46H1x8KbJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wcliao1962/2025_DL/blob/master/Softmax.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Softmax 函數** 是一種常用的激活函數，通常用於多分類問題的最後一層。它將輸入的向量轉換為一個概率分佈，使得每個元素的值在 0 到 1 之間，並且所有元素的總和為 1。\n",
        "\n",
        "---\n",
        "\n",
        "### **Softmax 函數的定義**\n",
        "對於一個輸入向量 $ z = [z_1, z_2, \\dots, z_n] $，Softmax 函數的計算公式如下：\n",
        "\n",
        "$$\n",
        "\\text{Softmax}(z_i) = \\frac{e^{z_i}}{\\sum_{j=1}^{n} e^{z_j}}\n",
        "$$\n",
        "\n",
        "其中：\n",
        "- $ z_i $ 是輸入向量的第 $ i $ 個元素。\n",
        "- $ e^{z_i} $ 是 $ z_i $ 的指數。\n",
        "- $ \\sum_{j=1}^{n} e^{z_j} $ 是所有元素的指數之和。\n",
        "\n",
        "---\n",
        "\n",
        "### **Softmax 的 Python 實現**\n",
        "以下是 Softmax 函數的 Python 實現：\n",
        "\n"
      ],
      "metadata": {
        "id": "ECJ2eHeXZap_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def softmax(z):\n",
        "    # 避免數值溢出：減去最大值\n",
        "    exp_z = np.exp(z - np.max(z, axis=-1, keepdims=True))\n",
        "    return exp_z / np.sum(exp_z, axis=-1, keepdims=True)"
      ],
      "metadata": {
        "id": "TAXmR74PdbUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### **Softmax 的計算示例**\n",
        "假設輸入向量為 $ z = [2.0, 1.0, 0.1] $，我們來計算 Softmax 的輸出。\n",
        "\n",
        "1. 計算指數：\n",
        "   $\n",
        "   e^{2.0} = 7.389, \\quad e^{1.0} = 2.718, \\quad e^{0.1} = 1.105\n",
        "   $\n",
        "\n",
        "2. 計算指數之和：\n",
        "   $\n",
        "   7.389 + 2.718 + 1.105 = 11.212\n",
        "   $\n",
        "\n",
        "3. 計算 Softmax：\n",
        "   $\n",
        "   \\text{Softmax}(z_1) = \\frac{7.389}{11.212} \\approx 0.659\n",
        "   $\n",
        "   $\n",
        "   \\text{Softmax}(z_2) = \\frac{2.718}{11.212} \\approx 0.242\n",
        "   $\n",
        "   $\n",
        "   \\text{Softmax}(z_3) = \\frac{1.105}{11.212} \\approx 0.099\n",
        "   $\n",
        "\n",
        "最終輸出為：\n",
        "$\n",
        "\\text{Softmax}(z) = [0.659, 0.242, 0.099]\n",
        "$\n",
        "\n",
        "---\n",
        "\n",
        "### **Softmax 的性質**\n",
        "1. **輸出是概率分佈**：\n",
        "   - 每個元素的值在 0 到 1 之間。\n",
        "   - 所有元素的總和為 1。\n",
        "\n",
        "2. **放大差異**：\n",
        "   - Softmax 會放大輸入向量中的較大值，使其對應的概率更高。\n",
        "\n",
        "3. **數值穩定性**：\n",
        "   - 在實現時，通常會減去輸入向量中的最大值（`z - max(z)`），以避免指數運算時的數值溢出。\n",
        "\n",
        "---\n",
        "\n",
        "### **批次輸入的 Softmax**\n",
        "如果輸入是一個批次的多個向量（例如形狀為 `(batch_size, n)` 的矩陣），Softmax 會對每個向量獨立計算。\n",
        "\n",
        "例如：\n",
        "```python\n",
        "z = np.array([[2.0, 1.0, 0.1],\n",
        "              [1.0, 2.0, 0.1]])  # 形狀 (2, 3)\n",
        "\n",
        "softmax(z)\n",
        "```\n",
        "輸出：\n",
        "```\n",
        "array([[0.659, 0.242, 0.099],\n",
        "       [0.242, 0.659, 0.099]])\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **總結**\n",
        "Softmax 函數是深度學習中常用的激活函數，特別適用於多分類問題。它的輸出是一個概率分佈，可以直觀地解釋為每個類別的概率。如果你有其他問題，歡迎隨時問我！😊"
      ],
      "metadata": {
        "id": "h7aMshgcc1S3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z = np.array([[2.0, 1.0, 0.1],\n",
        "              [1.0, 2.0, 0.1]])  # 形狀 (2, 3)\n",
        "\n",
        "softmax(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1zRUIXPdy1i",
        "outputId": "31b5b6de-e17c-434b-b990-59ad74501252"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.65900114, 0.24243297, 0.09856589],\n",
              "       [0.24243297, 0.65900114, 0.09856589]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxKExv1RZZpJ"
      },
      "outputs": [],
      "source": []
    }
  ]
}